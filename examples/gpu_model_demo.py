"""
DLFE-LSTM-WSI GPUä¼˜åŒ–æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨GPUä¼˜åŒ–çš„æ¨¡å‹æ¨¡å—è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹
"""

import torch
import torch.nn as nn
import numpy as np
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root / "src"))

# å¯¼å…¥GPUä¼˜åŒ–æ¨¡å—
from models import LSTMPredictor, ModelBuilder, MultiWeatherModel
from utils.gpu_dataloader import create_gpu_optimized_loaders

# åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†ç±»
class MockDLFEDataset(torch.utils.data.Dataset):
    """æ¨¡æ‹ŸDLFEç‰¹å¾æ•°æ®é›†ï¼Œç”¨äºæ¼”ç¤º"""

    def __init__(self, num_samples=1000, seq_len=24, feature_dim=30):
        self.num_samples = num_samples
        self.seq_len = seq_len
        self.feature_dim = feature_dim

        # ç”Ÿæˆæ¨¡æ‹Ÿçš„DLFEç‰¹å¾æ•°æ®
        np.random.seed(42)
        self.features = np.random.randn(num_samples, seq_len, feature_dim).astype(np.float32)

        # ç”Ÿæˆæ¨¡æ‹Ÿçš„åŠŸç‡ç›®æ ‡å€¼ï¼ˆå½’ä¸€åŒ–åˆ°[0,1]ï¼‰
        self.targets = np.random.beta(2, 2, size=(num_samples, 1)).astype(np.float32)

        # ç”Ÿæˆæ¨¡æ‹Ÿçš„å¤©æ°”ç±»å‹ (0:æ™´å¤©, 1:å¤šäº‘, 2:é˜´å¤©)
        self.weather_types = np.random.randint(0, 3, size=num_samples)

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return (
            torch.from_numpy(self.features[idx]),
            torch.from_numpy(self.targets[idx]),
            self.weather_types[idx]
        )


def demo_single_model():
    """æ¼”ç¤ºå•ä¸ªLSTMæ¨¡å‹çš„ä½¿ç”¨"""
    print("=== å•ä¸ªLSTMæ¨¡å‹æ¼”ç¤º ===")

    # åˆ›å»ºGPUä¼˜åŒ–çš„LSTMæ¨¡å‹
    model = LSTMPredictor(
        input_dim=30,
        hidden_dims=[100, 50],
        dropout_rates=[0.3, 0.2],
        use_cuda=True,
        use_mixed_precision=True
    )

    print(f"æ¨¡å‹è®¾å¤‡: {model.device}")
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # æ¨¡æ‹Ÿè¾“å…¥æ•°æ®
    batch_size = 16
    seq_len = 24
    input_data = torch.randn(batch_size, seq_len, 30)

    if torch.cuda.is_available():
        input_data = input_data.cuda()

    # å‰å‘ä¼ æ’­
    model.eval()
    with torch.no_grad():
        predictions, hidden_states = model(input_data)
        print(f"é¢„æµ‹ç»“æœå½¢çŠ¶: {predictions.shape}")
        print(f"é¢„æµ‹å€¼èŒƒå›´: [{predictions.min().item():.4f}, {predictions.max().item():.4f}]")

    print("å•ä¸ªLSTMæ¨¡å‹æ¼”ç¤ºå®Œæˆ!\n")


def demo_model_builder():
    """æ¼”ç¤ºæ¨¡å‹æ„å»ºå™¨çš„ä½¿ç”¨"""
    print("=== æ¨¡å‹æ„å»ºå™¨æ¼”ç¤º ===")

    # åˆ›å»ºæ¨¡å‹æ„å»ºå™¨
    builder = ModelBuilder()

    # æ˜¾ç¤ºGPUé…ç½®
    print("GPUé…ç½®ä¿¡æ¯:")
    for key, value in builder.gpu_config.items():
        print(f"  {key}: {value}")

    # æ„å»ºæ¨¡å‹
    model = builder.build_model(use_data_parallel=False)

    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = builder.create_optimizer_gpu(model, lr=0.001)
    print(f"ä¼˜åŒ–å™¨ç±»å‹: {type(optimizer).__name__}")

    # ä¼°ç®—å†…å­˜ä½¿ç”¨
    memory_info = builder.estimate_memory_usage(model, batch_size=64)
    print("\nå†…å­˜ä½¿ç”¨ä¼°ç®—:")
    for key, value in memory_info.items():
        if isinstance(value, float):
            print(f"  {key}: {value:.2f}")
        else:
            print(f"  {key}: {value}")

    print("æ¨¡å‹æ„å»ºå™¨æ¼”ç¤ºå®Œæˆ!\n")


def demo_multi_weather_model():
    """æ¼”ç¤ºå¤šå¤©æ°”æ¨¡å‹ç®¡ç†å™¨çš„ä½¿ç”¨"""
    print("=== å¤šå¤©æ°”æ¨¡å‹ç®¡ç†å™¨æ¼”ç¤º ===")

    # åˆ›å»ºæ¨¡å‹æ„å»ºå™¨å’Œå¤šå¤©æ°”ç®¡ç†å™¨
    builder = ModelBuilder()
    multi_model = MultiWeatherModel(builder, use_model_parallel=False)

    print(f"åˆ›å»ºçš„å¤©æ°”æ¨¡å‹: {list(multi_model.models.keys())}")

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    batch_size = 8
    seq_len = 24
    features = torch.randn(batch_size, seq_len, 30)
    weather_prob = torch.softmax(torch.randn(batch_size, 3), dim=1)

    if torch.cuda.is_available():
        features = features.cuda()
        weather_prob = weather_prob.cuda()

    # å•æ¨¡å‹é¢„æµ‹
    with torch.no_grad():
        sunny_pred = multi_model.predict_gpu_optimized(
            features, weather_type=0, use_ensemble=False
        )
        print(f"æ™´å¤©æ¨¡å‹é¢„æµ‹: {sunny_pred.shape}")

    # é›†æˆé¢„æµ‹
    with torch.no_grad():
        ensemble_pred = multi_model.predict_gpu_optimized(
            features, weather_prob=weather_prob, use_ensemble=True
        )
        print(f"é›†æˆé¢„æµ‹: {ensemble_pred.shape}")

    print("å¤šå¤©æ°”æ¨¡å‹ç®¡ç†å™¨æ¼”ç¤ºå®Œæˆ!\n")


def demo_gpu_dataloader():
    """æ¼”ç¤ºGPUä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨"""
    print("=== GPUä¼˜åŒ–æ•°æ®åŠ è½½å™¨æ¼”ç¤º ===")

    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†
    train_dataset = MockDLFEDataset(num_samples=800)
    val_dataset = MockDLFEDataset(num_samples=200)

    # åˆ›å»ºGPUä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨
    train_loader, val_loader, _ = create_gpu_optimized_loaders(
        train_dataset, val_dataset, batch_size=32
    )

    print(f"è®­ç»ƒé›†æ‰¹æ¬¡æ•°: {len(train_loader)}")
    print(f"éªŒè¯é›†æ‰¹æ¬¡æ•°: {len(val_loader)}")

    # æµ‹è¯•æ•°æ®åŠ è½½
    for batch_idx, (features, targets, weather_types) in enumerate(train_loader):
        print(f"æ‰¹æ¬¡ {batch_idx+1}:")
        print(f"  ç‰¹å¾å½¢çŠ¶: {features.shape}")
        print(f"  ç›®æ ‡å½¢çŠ¶: {targets.shape}")
        print(f"  å¤©æ°”ç±»å‹: {weather_types[:5].tolist()}")  # æ˜¾ç¤ºå‰5ä¸ª
        if batch_idx >= 2:  # åªæ˜¾ç¤ºå‰3ä¸ªæ‰¹æ¬¡
            break

    print("GPUä¼˜åŒ–æ•°æ®åŠ è½½å™¨æ¼”ç¤ºå®Œæˆ!\n")


def demo_training_loop():
    """æ¼”ç¤ºç®€å•çš„è®­ç»ƒå¾ªç¯"""
    print("=== è®­ç»ƒå¾ªç¯æ¼”ç¤º ===")

    # åˆ›å»ºæ•°æ®
    train_dataset = MockDLFEDataset(num_samples=200)
    val_dataset = MockDLFEDataset(num_samples=50)

    train_loader, val_loader, _ = create_gpu_optimized_loaders(
        train_dataset, val_dataset, batch_size=16
    )

    # åˆ›å»ºæ¨¡å‹å’Œä¼˜åŒ–å™¨
    builder = ModelBuilder()
    multi_model = MultiWeatherModel(builder)

    # é€‰æ‹©æ™´å¤©æ¨¡å‹è¿›è¡Œæ¼”ç¤ºè®­ç»ƒ
    model = multi_model.models['sunny']
    optimizer = builder.create_optimizer_gpu(model, lr=0.01)
    criterion = nn.MSELoss()

    if torch.cuda.is_available():
        criterion = criterion.cuda()

    # ç®€å•è®­ç»ƒå¾ªç¯ï¼ˆä»…æ¼”ç¤ºï¼‰
    model.train()
    for epoch in range(3):  # åªè®­ç»ƒ3ä¸ªepochç”¨äºæ¼”ç¤º
        train_loss = 0.0

        for batch_idx, (features, targets, _) in enumerate(train_loader):
            if torch.cuda.is_available():
                features = features.cuda()
                targets = targets.cuda()

            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            with torch.cuda.amp.autocast():
                predictions, _ = model(features)
                loss = criterion(predictions, targets)

            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

            if batch_idx >= 5:  # åªè®­ç»ƒå‡ ä¸ªæ‰¹æ¬¡ç”¨äºæ¼”ç¤º
                break

        print(f"Epoch {epoch+1}, å¹³å‡æŸå¤±: {train_loss/(batch_idx+1):.6f}")

    print("è®­ç»ƒå¾ªç¯æ¼”ç¤ºå®Œæˆ!\n")


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ DLFE-LSTM-WSI GPUä¼˜åŒ–æ¨¡å‹ä½¿ç”¨æ¼”ç¤º\n")

    try:
        demo_single_model()
        demo_model_builder()
        demo_multi_weather_model()
        demo_gpu_dataloader()
        demo_training_loop()

        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼GPUä¼˜åŒ–æ¨¡å‹æ¨¡å—å·¥ä½œæ­£å¸¸ã€‚")

    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()