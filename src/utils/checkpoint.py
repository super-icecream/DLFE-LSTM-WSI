# -*- coding: utf-8 -*-
"""
æ¨¡å‹æ£€æŸ¥ç‚¹ç®¡ç†æ¨¡å—
è´Ÿè´£æ¨¡å‹çš„ä¿å­˜ã€åŠ è½½å’Œç‰ˆæœ¬ç®¡ç†
æ”¯æŒæ–­ç‚¹ç»­è®­å’Œæœ€ä½³æ¨¡å‹è¿½è¸ª
"""

import os
import json
import shutil
import torch
import torch.nn as nn
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
import hashlib
import pickle


class CheckpointManager:
    """
    æ£€æŸ¥ç‚¹ç®¡ç†å™¨
    
    åŠŸèƒ½ï¼š
    - æ¨¡å‹æƒé‡ä¿å­˜/åŠ è½½
    - è®­ç»ƒçŠ¶æ€ä¿å­˜/æ¢å¤
    - æœ€ä½³æ¨¡å‹ç®¡ç†
    - æ–­ç‚¹ç»­è®­æ”¯æŒ
    - æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶
    """
    
    def __init__(self, 
                 checkpoint_dir: str = './experiments/checkpoints',
                 max_checkpoints: int = 5,
                 save_best_only: bool = False,
                 monitor_metric: str = 'val_loss',
                 mode: str = 'min'):
        """
        åˆå§‹åŒ–æ£€æŸ¥ç‚¹ç®¡ç†å™¨
        
        Args:
            checkpoint_dir: æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
            max_checkpoints: æœ€å¤šä¿ç•™çš„æ£€æŸ¥ç‚¹æ•°é‡
            save_best_only: æ˜¯å¦åªä¿å­˜æœ€ä½³æ¨¡å‹
            monitor_metric: ç›‘æ§çš„æŒ‡æ ‡åç§°
            mode: 'min'æˆ–'max'ï¼ŒæŒ‡æ ‡ä¼˜åŒ–æ–¹å‘
        """
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        self.max_checkpoints = max_checkpoints
        self.save_best_only = save_best_only
        self.monitor_metric = monitor_metric
        self.mode = mode
        
        # æœ€ä½³æŒ‡æ ‡è¿½è¸ª
        self.best_metric = float('inf') if mode == 'min' else float('-inf')
        self.best_epoch = 0
        
        # æ£€æŸ¥ç‚¹å†å²
        self.checkpoint_history = []
        self._load_history()
    
    def save_checkpoint(self,
                       model: nn.Module,
                       optimizer: torch.optim.Optimizer,
                       epoch: int,
                       metrics: Dict[str, float],
                       scheduler: Optional[Any] = None,
                       scaler: Optional[Any] = None,
                       extra_info: Optional[Dict] = None) -> Optional[Path]:
        """
        ä¿å­˜æ£€æŸ¥ç‚¹
        
        Args:
            model: æ¨¡å‹
            optimizer: ä¼˜åŒ–å™¨
            epoch: å½“å‰epoch
            metrics: è¯„ä¼°æŒ‡æ ‡
            scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
            scaler: æ··åˆç²¾åº¦ç¼©æ”¾å™¨
            extra_info: é¢å¤–ä¿¡æ¯
            
        Returns:
            ä¿å­˜è·¯å¾„ï¼ˆå¦‚æœä¿å­˜ï¼‰
        """
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜
        current_metric = metrics.get(self.monitor_metric, 0)
        is_best = self._is_better(current_metric, self.best_metric)
        
        if self.save_best_only and not is_best:
            return None
        
        # æ›´æ–°æœ€ä½³æŒ‡æ ‡
        if is_best:
            self.best_metric = current_metric
            self.best_epoch = epoch
        
        # æ„å»ºæ£€æŸ¥ç‚¹
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'metrics': metrics,
            'best_metric': self.best_metric,
            'best_epoch': self.best_epoch,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'model_config': self._get_model_config(model),
        }
        
        # æ·»åŠ å¯é€‰ç»„ä»¶
        if scheduler is not None:
            checkpoint['scheduler_state_dict'] = scheduler.state_dict()
        
        if scaler is not None:
            checkpoint['scaler_state_dict'] = scaler.state_dict()
        
        if extra_info is not None:
            checkpoint['extra_info'] = extra_info
        
        # è®¡ç®—æ£€æŸ¥ç‚¹å“ˆå¸Œï¼ˆç”¨äºç‰ˆæœ¬æ§åˆ¶ï¼‰
        checkpoint['hash'] = self._calculate_hash(checkpoint['model_state_dict'])
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if is_best:
            save_path = self.checkpoint_dir / 'best_model.pth'
        else:
            save_path = self.checkpoint_dir / f'checkpoint_epoch_{epoch:04d}.pth'
        
        torch.save(checkpoint, save_path)
        
        # è®°å½•å†å²
        self._add_to_history({
            'path': str(save_path),
            'epoch': epoch,
            'metrics': metrics,
            'is_best': is_best,
            'timestamp': checkpoint['timestamp'],
            'hash': checkpoint['hash']
        })
        
        # æ¸…ç†æ—§æ£€æŸ¥ç‚¹
        if not self.save_best_only:
            self._cleanup_old_checkpoints()
        
        print(f"{'ğŸŒŸ æœ€ä½³' if is_best else 'âœ…'} æ£€æŸ¥ç‚¹å·²ä¿å­˜: {save_path}")
        
        return save_path
    
    def load_checkpoint(self,
                       model: nn.Module,
                       optimizer: Optional[torch.optim.Optimizer] = None,
                       scheduler: Optional[Any] = None,
                       scaler: Optional[Any] = None,
                       checkpoint_path: Optional[str] = None,
                       load_best: bool = False,
                       strict: bool = True) -> Dict[str, Any]:
        """
        åŠ è½½æ£€æŸ¥ç‚¹
        
        Args:
            model: æ¨¡å‹
            optimizer: ä¼˜åŒ–å™¨
            scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
            scaler: æ··åˆç²¾åº¦ç¼©æ”¾å™¨
            checkpoint_path: æŒ‡å®šæ£€æŸ¥ç‚¹è·¯å¾„
            load_best: æ˜¯å¦åŠ è½½æœ€ä½³æ¨¡å‹
            strict: æ˜¯å¦ä¸¥æ ¼åŒ¹é…æ¨¡å‹å‚æ•°
            
        Returns:
            æ£€æŸ¥ç‚¹ä¿¡æ¯å­—å…¸
        """
        # ç¡®å®šåŠ è½½è·¯å¾„
        if checkpoint_path:
            load_path = Path(checkpoint_path)
        elif load_best:
            load_path = self.checkpoint_dir / 'best_model.pth'
        else:
            # åŠ è½½æœ€æ–°æ£€æŸ¥ç‚¹
            load_path = self._get_latest_checkpoint()
        
        if not load_path or not load_path.exists():
            raise FileNotFoundError(f"æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {load_path}")
        
        print(f"ğŸ“‚ åŠ è½½æ£€æŸ¥ç‚¹: {load_path}")
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint = torch.load(load_path, map_location='cpu')
        
        # æ¢å¤æ¨¡å‹çŠ¶æ€
        model.load_state_dict(checkpoint['model_state_dict'], strict=strict)
        
        # æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€
        if optimizer is not None and 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        # æ¢å¤è°ƒåº¦å™¨çŠ¶æ€
        if scheduler is not None and 'scheduler_state_dict' in checkpoint:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        # æ¢å¤ç¼©æ”¾å™¨çŠ¶æ€
        if scaler is not None and 'scaler_state_dict' in checkpoint:
            scaler.load_state_dict(checkpoint['scaler_state_dict'])
        
        # æ›´æ–°æœ€ä½³æŒ‡æ ‡
        if 'best_metric' in checkpoint:
            self.best_metric = checkpoint['best_metric']
            self.best_epoch = checkpoint.get('best_epoch', 0)
        
        print(f"âœ… æ£€æŸ¥ç‚¹åŠ è½½æˆåŠŸ | Epoch: {checkpoint['epoch']}")
        
        # éªŒè¯å“ˆå¸Œ
        if 'hash' in checkpoint:
            current_hash = self._calculate_hash(checkpoint['model_state_dict'])
            if current_hash != checkpoint['hash']:
                print("âš ï¸ è­¦å‘Š: æ£€æŸ¥ç‚¹å“ˆå¸Œä¸åŒ¹é…ï¼Œæ¨¡å‹å¯èƒ½å·²è¢«ä¿®æ”¹")
        
        return checkpoint
    
    def save_model_only(self,
                       model: nn.Module,
                       save_path: Optional[str] = None,
                       model_name: Optional[str] = None) -> Path:
        """
        ä»…ä¿å­˜æ¨¡å‹æƒé‡
        
        Args:
            model: æ¨¡å‹
            save_path: ä¿å­˜è·¯å¾„
            model_name: æ¨¡å‹åç§°
            
        Returns:
            ä¿å­˜è·¯å¾„
        """
        if save_path:
            save_path = Path(save_path)
        else:
            model_name = model_name or 'model'
            save_path = self.checkpoint_dir / f'{model_name}.pth'
        
        # ä¿å­˜æ¨¡å‹
        torch.save({
            'model_state_dict': model.state_dict(),
            'model_config': self._get_model_config(model),
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }, save_path)
        
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_path}")
        return save_path
    
    def load_model_only(self,
                       model: nn.Module,
                       model_path: str,
                       strict: bool = True) -> nn.Module:
        """
        ä»…åŠ è½½æ¨¡å‹æƒé‡
        
        Args:
            model: æ¨¡å‹
            model_path: æ¨¡å‹è·¯å¾„
            strict: æ˜¯å¦ä¸¥æ ¼åŒ¹é…
            
        Returns:
            åŠ è½½åçš„æ¨¡å‹
        """
        checkpoint = torch.load(model_path, map_location='cpu')
        
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'], strict=strict)
        else:
            # å…¼å®¹ç›´æ¥ä¿å­˜çš„state_dict
            model.load_state_dict(checkpoint, strict=strict)
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
        return model
    
    def export_model(self,
                    model: nn.Module,
                    export_path: str,
                    input_shape: Tuple[int, ...],
                    export_format: str = 'onnx'):
        """
        å¯¼å‡ºæ¨¡å‹åˆ°å…¶ä»–æ ¼å¼
        
        Args:
            model: æ¨¡å‹
            export_path: å¯¼å‡ºè·¯å¾„
            input_shape: è¾“å…¥å½¢çŠ¶
            export_format: å¯¼å‡ºæ ¼å¼ ('onnx', 'torchscript')
        """
        model.eval()
        dummy_input = torch.randn(1, *input_shape)
        
        if export_format == 'onnx':
            torch.onnx.export(
                model,
                dummy_input,
                export_path,
                export_params=True,
                opset_version=11,
                do_constant_folding=True,
                input_names=['input'],
                output_names=['output'],
                dynamic_axes={'input': {0: 'batch_size'},
                            'output': {0: 'batch_size'}}
            )
            print(f"ğŸ“¦ æ¨¡å‹å·²å¯¼å‡ºä¸ºONNX: {export_path}")
            
        elif export_format == 'torchscript':
            traced = torch.jit.trace(model, dummy_input)
            traced.save(export_path)
            print(f"ğŸ“¦ æ¨¡å‹å·²å¯¼å‡ºä¸ºTorchScript: {export_path}")
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {export_format}")
    
    def get_checkpoint_info(self, checkpoint_path: str) -> Dict[str, Any]:
        """
        è·å–æ£€æŸ¥ç‚¹ä¿¡æ¯ï¼ˆä¸åŠ è½½æƒé‡ï¼‰
        
        Args:
            checkpoint_path: æ£€æŸ¥ç‚¹è·¯å¾„
            
        Returns:
            æ£€æŸ¥ç‚¹ä¿¡æ¯
        """
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # ç§»é™¤å¤§çš„å¼ é‡æ•°æ®
        info = {
            'epoch': checkpoint.get('epoch', 0),
            'metrics': checkpoint.get('metrics', {}),
            'timestamp': checkpoint.get('timestamp', 'Unknown'),
            'best_metric': checkpoint.get('best_metric', None),
            'best_epoch': checkpoint.get('best_epoch', None),
            'hash': checkpoint.get('hash', None),
            'extra_info': checkpoint.get('extra_info', {})
        }
        
        return info
    
    def list_checkpoints(self) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹
        
        Returns:
            æ£€æŸ¥ç‚¹ä¿¡æ¯åˆ—è¡¨
        """
        checkpoints = []
        
        for ckpt_path in self.checkpoint_dir.glob('*.pth'):
            try:
                info = self.get_checkpoint_info(ckpt_path)
                info['path'] = str(ckpt_path)
                info['size_mb'] = ckpt_path.stat().st_size / 1024 / 1024
                checkpoints.append(info)
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è¯»å–æ£€æŸ¥ç‚¹ {ckpt_path}: {e}")
        
        # æŒ‰epochæ’åº
        checkpoints.sort(key=lambda x: x.get('epoch', 0))
        
        return checkpoints
    
    def compare_checkpoints(self,
                           ckpt1_path: str,
                           ckpt2_path: str) -> Dict[str, Any]:
        """
        æ¯”è¾ƒä¸¤ä¸ªæ£€æŸ¥ç‚¹
        
        Args:
            ckpt1_path: ç¬¬ä¸€ä¸ªæ£€æŸ¥ç‚¹è·¯å¾„
            ckpt2_path: ç¬¬äºŒä¸ªæ£€æŸ¥ç‚¹è·¯å¾„
            
        Returns:
            æ¯”è¾ƒç»“æœ
        """
        info1 = self.get_checkpoint_info(ckpt1_path)
        info2 = self.get_checkpoint_info(ckpt2_path)
        
        comparison = {
            'checkpoint_1': ckpt1_path,
            'checkpoint_2': ckpt2_path,
            'epoch_diff': info2['epoch'] - info1['epoch'],
            'metrics_comparison': {}
        }
        
        # æ¯”è¾ƒæŒ‡æ ‡
        for metric in set(info1.get('metrics', {}).keys()) | set(info2.get('metrics', {}).keys()):
            val1 = info1.get('metrics', {}).get(metric, None)
            val2 = info2.get('metrics', {}).get(metric, None)
            
            if val1 is not None and val2 is not None:
                diff = val2 - val1
                improvement = diff if metric != 'loss' else -diff
                comparison['metrics_comparison'][metric] = {
                    'ckpt1': val1,
                    'ckpt2': val2,
                    'difference': diff,
                    'improvement': improvement,
                    'improvement_pct': (improvement / abs(val1)) * 100 if val1 != 0 else 0
                }
        
        return comparison
    
    def _is_better(self, current: float, best: float) -> bool:
        """åˆ¤æ–­å½“å‰æŒ‡æ ‡æ˜¯å¦æ›´å¥½"""
        if self.mode == 'min':
            return current < best
        else:
            return current > best
    
    def _get_model_config(self, model: nn.Module) -> Dict:
        """è·å–æ¨¡å‹é…ç½®"""
        config = {
            'class_name': model.__class__.__name__,
            'num_parameters': sum(p.numel() for p in model.parameters()),
            'trainable_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad)
        }
        
        # å°è¯•è·å–æ¨¡å‹çš„é…ç½®å±æ€§
        if hasattr(model, 'config'):
            config['model_config'] = model.config
        
        return config
    
    def _calculate_hash(self, state_dict: Dict) -> str:
        """è®¡ç®—çŠ¶æ€å­—å…¸å“ˆå¸Œå€¼"""
        # å°†çŠ¶æ€å­—å…¸è½¬æ¢ä¸ºå­—èŠ‚
        state_bytes = pickle.dumps(
            {k: v.cpu().numpy() for k, v in state_dict.items()},
            protocol=pickle.HIGHEST_PROTOCOL
        )
        
        # è®¡ç®—MD5å“ˆå¸Œ
        return hashlib.md5(state_bytes).hexdigest()
    
    def _get_latest_checkpoint(self) -> Optional[Path]:
        """è·å–æœ€æ–°çš„æ£€æŸ¥ç‚¹"""
        checkpoints = list(self.checkpoint_dir.glob('checkpoint_epoch_*.pth'))
        
        if not checkpoints:
            return None
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        checkpoints.sort(key=lambda x: x.stat().st_mtime)
        return checkpoints[-1]
    
    def _cleanup_old_checkpoints(self):
        """æ¸…ç†æ—§çš„æ£€æŸ¥ç‚¹"""
        checkpoints = list(self.checkpoint_dir.glob('checkpoint_epoch_*.pth'))
        
        if len(checkpoints) <= self.max_checkpoints:
            return
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        checkpoints.sort(key=lambda x: x.stat().st_mtime)
        
        # åˆ é™¤æœ€æ—§çš„æ£€æŸ¥ç‚¹
        for ckpt in checkpoints[:-self.max_checkpoints]:
            ckpt.unlink()
            print(f"ğŸ—‘ï¸ åˆ é™¤æ—§æ£€æŸ¥ç‚¹: {ckpt}")
            
            # ä»å†å²ä¸­ç§»é™¤
            self.checkpoint_history = [
                h for h in self.checkpoint_history 
                if h['path'] != str(ckpt)
            ]
    
    def _load_history(self):
        """åŠ è½½æ£€æŸ¥ç‚¹å†å²"""
        history_path = self.checkpoint_dir / 'checkpoint_history.json'
        
        if history_path.exists():
            with open(history_path, 'r', encoding='utf-8') as f:
                self.checkpoint_history = json.load(f)
    
    def _add_to_history(self, record: Dict):
        """æ·»åŠ åˆ°å†å²è®°å½•"""
        self.checkpoint_history.append(record)
        
        # ä¿å­˜å†å²
        history_path = self.checkpoint_dir / 'checkpoint_history.json'
        with open(history_path, 'w', encoding='utf-8') as f:
            json.dump(self.checkpoint_history, f, indent=2, ensure_ascii=False)
    
    def clear_all_checkpoints(self, confirm: bool = False):
        """
        æ¸…é™¤æ‰€æœ‰æ£€æŸ¥ç‚¹
        
        Args:
            confirm: ç¡®è®¤åˆ é™¤
        """
        if not confirm:
            print("âš ï¸ è­¦å‘Š: æ­¤æ“ä½œå°†åˆ é™¤æ‰€æœ‰æ£€æŸ¥ç‚¹!")
            print("å¦‚éœ€ç»§ç»­ï¼Œè¯·è®¾ç½® confirm=True")
            return
        
        # åˆ é™¤æ‰€æœ‰.pthæ–‡ä»¶
        for ckpt_path in self.checkpoint_dir.glob('*.pth'):
            ckpt_path.unlink()
            print(f"ğŸ—‘ï¸ å·²åˆ é™¤: {ckpt_path}")
        
        # æ¸…ç©ºå†å²
        self.checkpoint_history = []
        history_path = self.checkpoint_dir / 'checkpoint_history.json'
        if history_path.exists():
            history_path.unlink()
        
        # é‡ç½®æœ€ä½³æŒ‡æ ‡
        self.best_metric = float('inf') if self.mode == 'min' else float('-inf')
        self.best_epoch = 0
        
        print("âœ… æ‰€æœ‰æ£€æŸ¥ç‚¹å·²æ¸…é™¤")


# å•å…ƒæµ‹è¯•
if __name__ == "__main__":
    import torch.nn as nn
    import torch.optim as optim
    
    # åˆ›å»ºç®€å•æ¨¡å‹ç”¨äºæµ‹è¯•
    class SimpleModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.fc = nn.Linear(10, 1)
        
        def forward(self, x):
            return self.fc(x)
    
    # åˆ›å»ºæ£€æŸ¥ç‚¹ç®¡ç†å™¨
    ckpt_manager = CheckpointManager(
        checkpoint_dir='./test_checkpoints',
        max_checkpoints=3,
        monitor_metric='val_loss',
        mode='min'
    )
    
    # åˆ›å»ºæ¨¡å‹å’Œä¼˜åŒ–å™¨
    model = SimpleModel()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    for epoch in range(5):
        # æ¨¡æ‹Ÿè®­ç»ƒ...
        metrics = {
            'train_loss': 0.5 - epoch * 0.1,
            'val_loss': 0.6 - epoch * 0.08,
            'accuracy': 0.8 + epoch * 0.03
        }
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        ckpt_manager.save_checkpoint(
            model=model,
            optimizer=optimizer,
            epoch=epoch,
            metrics=metrics,
            extra_info={'learning_rate': 0.001}
        )
    
    # åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹
    print("\næ‰€æœ‰æ£€æŸ¥ç‚¹:")
    for ckpt in ckpt_manager.list_checkpoints():
        print(f"  Epoch {ckpt['epoch']}: {ckpt['metrics']}")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    print("\nåŠ è½½æœ€ä½³æ¨¡å‹:")
    checkpoint = ckpt_manager.load_checkpoint(
        model=model,
        optimizer=optimizer,
        load_best=True
    )
    print(f"  æœ€ä½³Epoch: {checkpoint['epoch']}")
    print(f"  æœ€ä½³æŒ‡æ ‡: {checkpoint['metrics']}")