# -*- coding: utf-8 -*-
"""
é…ç½®åŠ è½½å™¨æ¨¡å—
è´Ÿè´£åŠ è½½ã€éªŒè¯å’Œç®¡ç†YAMLé…ç½®æ–‡ä»¶
æ”¯æŒç¯å¢ƒå˜é‡æ›¿æ¢å’Œé…ç½®åˆå¹¶åŠŸèƒ½
"""

import os
import yaml
import json
from pathlib import Path
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass, field
import logging
from datetime import datetime
import copy

logger = logging.getLogger(__name__)


@dataclass
class ConfigSchema:
    """é…ç½®æ¨¡å¼éªŒè¯ç±»"""
    required_fields: List[str] = field(default_factory=list)
    optional_fields: List[str] = field(default_factory=list)
    field_types: Dict[str, type] = field(default_factory=dict)
    field_ranges: Dict[str, tuple] = field(default_factory=dict)


class ConfigLoader:
    """
    é…ç½®åŠ è½½å™¨
    
    åŠŸèƒ½ï¼š
    - åŠ è½½YAML/JSONé…ç½®æ–‡ä»¶
    - æ”¯æŒç¯å¢ƒå˜é‡æ›¿æ¢
    - é…ç½®éªŒè¯å’Œç±»å‹æ£€æŸ¥
    - é…ç½®åˆå¹¶å’Œè¦†ç›–
    - é…ç½®ç¼“å­˜ç®¡ç†
    """
    
    def __init__(self, 
                 config_dir: str = './config',
                 env_prefix: str = 'DLFE',
                 cache_enabled: bool = True):
        """
        åˆå§‹åŒ–é…ç½®åŠ è½½å™¨
        
        Args:
            config_dir: é…ç½®æ–‡ä»¶ç›®å½•
            env_prefix: ç¯å¢ƒå˜é‡å‰ç¼€
            cache_enabled: æ˜¯å¦å¯ç”¨é…ç½®ç¼“å­˜
        """
        self.config_dir = Path(config_dir)
        self.env_prefix = env_prefix
        self.cache_enabled = cache_enabled
        self._cache: Dict[str, Dict] = {}
        
        # ç¡®ä¿é…ç½®ç›®å½•å­˜åœ¨
        self.config_dir.mkdir(parents=True, exist_ok=True)
        
        # å®šä¹‰é»˜è®¤é…ç½®æ¨¡å¼
        self.schema = self._define_schema()
    
    def _define_schema(self) -> ConfigSchema:
        """å®šä¹‰é…ç½®æ–‡ä»¶æ¨¡å¼"""
        schema = ConfigSchema()
        
        # å¿…éœ€å­—æ®µ
        schema.required_fields = [
            'project.name',
            'project.version',
            'data.dataset',
            'model.lstm.hidden_sizes',
            'training.batch_size',
            'training.epochs'
        ]
        
        # å­—æ®µç±»å‹
        schema.field_types = {
            'project.name': str,
            'project.version': str,
            'data.train_ratio': float,
            'data.val_ratio': float,
            'data.test_ratio': float,
            'model.lstm.hidden_sizes': list,
            'model.lstm.dropout_rates': list,
            'training.batch_size': int,
            'training.epochs': int,
            'training.learning_rate': float
        }
        
        # å­—æ®µèŒƒå›´
        schema.field_ranges = {
            'data.train_ratio': (0.0, 1.0),
            'data.val_ratio': (0.0, 1.0),
            'data.test_ratio': (0.0, 1.0),
            'training.batch_size': (1, 1024),
            'training.epochs': (1, 10000),
            'training.learning_rate': (1e-6, 1.0)
        }
        
        return schema
    
    def load(self, 
             config_path: Union[str, Path],
             override_with_env: bool = True,
             validate: bool = True) -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            override_with_env: æ˜¯å¦ç”¨ç¯å¢ƒå˜é‡è¦†ç›–
            validate: æ˜¯å¦éªŒè¯é…ç½®
            
        Returns:
            é…ç½®å­—å…¸
        """
        config_path = Path(config_path)
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = str(config_path.absolute())
        if self.cache_enabled and cache_key in self._cache:
            logger.debug(f"ä»ç¼“å­˜åŠ è½½é…ç½®: {cache_key}")
            return copy.deepcopy(self._cache[cache_key])
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        if not config_path.exists():
            # å°è¯•åœ¨é…ç½®ç›®å½•ä¸­æŸ¥æ‰¾
            config_path = self.config_dir / config_path
            if not config_path.exists():
                raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        print(f"ğŸ“„ åŠ è½½é…ç½®: {config_path}")
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åŠ è½½å™¨
        if config_path.suffix in ['.yaml', '.yml']:
            config = self._load_yaml(config_path)
        elif config_path.suffix == '.json':
            config = self._load_json(config_path)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é…ç½®æ–‡ä»¶æ ¼å¼: {config_path.suffix}")
        
        # ç¯å¢ƒå˜é‡æ›¿æ¢
        if override_with_env:
            config = self._override_with_env(config)
        
        # é…ç½®éªŒè¯
        if validate:
            self.validate(config)
        
        # ç¼“å­˜é…ç½®
        if self.cache_enabled:
            self._cache[cache_key] = copy.deepcopy(config)
        
        return config
    
    def _load_yaml(self, path: Path) -> Dict[str, Any]:
        """åŠ è½½YAMLæ–‡ä»¶"""
        with open(path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _load_json(self, path: Path) -> Dict[str, Any]:
        """åŠ è½½JSONæ–‡ä»¶"""
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _override_with_env(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä½¿ç”¨ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®
        
        ç¯å¢ƒå˜é‡æ ¼å¼: DLFE_SECTION_KEY=value
        ä¾‹å¦‚: DLFE_TRAINING_BATCH_SIZE=128
        """
        def update_nested_dict(d: dict, keys: list, value: Any):
            """æ›´æ–°åµŒå¥—å­—å…¸"""
            key = keys[0]
            if len(keys) == 1:
                # å°è¯•ç±»å‹è½¬æ¢
                if key in d and isinstance(d[key], bool):
                    value = value.lower() in ['true', '1', 'yes']
                elif key in d and isinstance(d[key], int):
                    value = int(value)
                elif key in d and isinstance(d[key], float):
                    value = float(value)
                d[key] = value
            else:
                if key not in d:
                    d[key] = {}
                update_nested_dict(d[key], keys[1:], value)
        
        # æ‰«æç¯å¢ƒå˜é‡
        for env_key, env_value in os.environ.items():
            if env_key.startswith(self.env_prefix + '_'):
                # è§£æç¯å¢ƒå˜é‡é”®
                config_keys = env_key[len(self.env_prefix)+1:].lower().split('_')
                try:
                    update_nested_dict(config, config_keys, env_value)
                    logger.debug(f"ç¯å¢ƒå˜é‡è¦†ç›–: {env_key}={env_value}")
                except Exception as e:
                    logger.warning(f"ç¯å¢ƒå˜é‡è¦†ç›–å¤±è´¥: {env_key}={env_value}, é”™è¯¯: {e}")
        
        return config
    
    def validate(self, config: Dict[str, Any]) -> bool:
        """
        éªŒè¯é…ç½®
        
        Args:
            config: é…ç½®å­—å…¸
            
        Returns:
            æ˜¯å¦éªŒè¯é€šè¿‡
            
        Raises:
            ValueError: é…ç½®éªŒè¯å¤±è´¥
        """
        def get_nested_value(d: dict, keys: str):
            """è·å–åµŒå¥—å­—å…¸å€¼"""
            keys_list = keys.split('.')
            value = d
            for key in keys_list:
                if isinstance(value, dict) and key in value:
                    value = value[key]
                else:
                    return None
            return value
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        for field in self.schema.required_fields:
            value = get_nested_value(config, field)
            if value is None:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€é…ç½®å­—æ®µ: {field}")
        
        # æ£€æŸ¥å­—æ®µç±»å‹
        for field, expected_type in self.schema.field_types.items():
            value = get_nested_value(config, field)
            if value is not None and not isinstance(value, expected_type):
                raise ValueError(
                    f"é…ç½®å­—æ®µç±»å‹é”™è¯¯: {field}, "
                    f"æœŸæœ› {expected_type.__name__}, "
                    f"å®é™… {type(value).__name__}"
                )
        
        # æ£€æŸ¥å­—æ®µèŒƒå›´
        for field, (min_val, max_val) in self.schema.field_ranges.items():
            value = get_nested_value(config, field)
            if value is not None:
                if isinstance(value, (int, float)):
                    if not (min_val <= value <= max_val):
                        raise ValueError(
                            f"é…ç½®å­—æ®µè¶…å‡ºèŒƒå›´: {field}={value}, "
                            f"æœ‰æ•ˆèŒƒå›´: [{min_val}, {max_val}]"
                        )
        
        # ç‰¹æ®ŠéªŒè¯ï¼šæ•°æ®é›†åˆ’åˆ†æ¯”ä¾‹
        train_ratio = get_nested_value(config, 'data.train_ratio')
        val_ratio = get_nested_value(config, 'data.val_ratio')
        test_ratio = get_nested_value(config, 'data.test_ratio')
        
        if train_ratio and val_ratio and test_ratio:
            total_ratio = train_ratio + val_ratio + test_ratio
            if abs(total_ratio - 1.0) > 1e-6:
                raise ValueError(
                    f"æ•°æ®é›†åˆ’åˆ†æ¯”ä¾‹ä¹‹å’Œå¿…é¡»ä¸º1.0, å½“å‰: {total_ratio}"
                )
        
        # é…ç½®éªŒè¯é€šè¿‡ï¼Œæ— éœ€è¾“å‡º
        return True
    
    def merge_configs(self, 
                     base_config: Dict[str, Any],
                     *override_configs: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆå¹¶å¤šä¸ªé…ç½®
        
        Args:
            base_config: åŸºç¡€é…ç½®
            override_configs: è¦†ç›–é…ç½®ï¼ˆå¯å¤šä¸ªï¼‰
            
        Returns:
            åˆå¹¶åçš„é…ç½®
        """
        def deep_merge(base: dict, override: dict) -> dict:
            """æ·±åº¦åˆå¹¶å­—å…¸"""
            result = copy.deepcopy(base)
            for key, value in override.items():
                if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                    result[key] = deep_merge(result[key], value)
                else:
                    result[key] = copy.deepcopy(value)
            return result
        
        merged = copy.deepcopy(base_config)
        for override in override_configs:
            merged = deep_merge(merged, override)
        
        return merged
    
    def save(self, 
             config: Dict[str, Any],
             save_path: Union[str, Path],
             format: str = 'yaml'):
        """
        ä¿å­˜é…ç½®æ–‡ä»¶
        
        Args:
            config: é…ç½®å­—å…¸
            save_path: ä¿å­˜è·¯å¾„
            format: ä¿å­˜æ ¼å¼ ('yaml' æˆ– 'json')
        """
        save_path = Path(save_path)
        save_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(save_path, 'w', encoding='utf-8') as f:
            if format == 'yaml':
                yaml.dump(config, f, default_flow_style=False, 
                         allow_unicode=True, sort_keys=False)
            elif format == 'json':
                json.dump(config, f, indent=2, ensure_ascii=False)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ä¿å­˜æ ¼å¼: {format}")
        
        logger.info(f"é…ç½®å·²ä¿å­˜è‡³: {save_path}")
    
    def get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        default_config = {
            'project': {
                'name': 'DLFE-LSTM-WSI',
                'version': '1.0.0',
                'device': 'cuda:0'
            },
            'data': {
                'dataset': 'ç”˜è‚ƒå…‰ä¼åŠŸç‡é¢„æµ‹æ•°æ®é›†',
                'train_ratio': 0.7,
                'val_ratio': 0.2,
                'test_ratio': 0.1,
                'sequence_length': 30,
                'sampling_rate': '5T'
            },
            'preprocessing': {
                'vmd': {
                    'n_modes': 5,
                    'alpha': 2000,
                    'tolerance': 1e-6
                },
                'normalization': {
                    'method': 'minmax',
                    'feature_range': [0, 1]
                }
            },
            'feature_engineering': {
                'ci_thresholds': [0.2, 0.6],
                'wsi_thresholds': [0.3, 0.7],
                'fusion_weights': {
                    'ci': 0.7,
                    'wsi': 0.3
                },
                'dpsr': {
                    'embedding_dim': 30,
                    'neighborhood_size': 10
                },
                'dlfe': {
                    'target_dim': 30,
                    'alpha': 2**-10,
                    'beta': 0.1
                }
            },
            'model': {
                'lstm': {
                    'hidden_sizes': [100, 50],
                    'dropout_rates': [0.3, 0.2],
                    'activation': 'tanh'
                }
            },
            'training': {
                'batch_size': 64,
                'epochs': 100,
                'learning_rate': 0.05,
                'optimizer': 'SGDM',
                'scheduler': {
                    'type': 'StepLR',
                    'step_size': 30,
                    'gamma': 0.1
                }
            },
            'adaptive': {
                'error_window': 100,
                'trigger_thresholds': {
                    'level1': 0.1,
                    'level2': 0.15,
                    'level3': 0.05,
                    'level4': 5
                }
            },
            'evaluation': {
                'metrics': ['RMSE', 'MAE', 'NRMSE', 'R2', 'MAPE'],
                'horizons': [1, 3, 6],
                'confidence_level': 0.95
            }
        }
        
        return default_config
    
    def clear_cache(self):
        """æ¸…ç©ºé…ç½®ç¼“å­˜"""
        self._cache.clear()
        logger.debug("é…ç½®ç¼“å­˜å·²æ¸…ç©º")


# å•å…ƒæµ‹è¯•
if __name__ == "__main__":
    # åˆ›å»ºé…ç½®åŠ è½½å™¨
    loader = ConfigLoader()
    
    # è·å–é»˜è®¤é…ç½®
    default_config = loader.get_default_config()
    print("é»˜è®¤é…ç½®:")
    print(yaml.dump(default_config, default_flow_style=False))
    
    # ä¿å­˜é»˜è®¤é…ç½®
    loader.save(default_config, './config/default.yaml')
    
    # åŠ è½½é…ç½®
    config = loader.load('./config/default.yaml')
    print("\nåŠ è½½çš„é…ç½®:")
    print(f"é¡¹ç›®åç§°: {config['project']['name']}")
    print(f"æ‰¹å¤§å°: {config['training']['batch_size']}")
    
    # åˆå¹¶é…ç½®
    override = {'training': {'batch_size': 128}}
    merged = loader.merge_configs(config, override)
    print(f"\nåˆå¹¶åçš„æ‰¹å¤§å°: {merged['training']['batch_size']}")